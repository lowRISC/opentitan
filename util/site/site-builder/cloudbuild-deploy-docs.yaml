# Copyright lowRISC contributors (OpenTitan project).
# Licensed under the Apache License, Version 2.0, see LICENSE for details.
# SPDX-License-Identifier: Apache-2.0

steps:
# Use the 'gold-hybrid-255313/builder' container image (util/container/Dockerfile) to perform the build
# > We override the 'ENTRYPOINT', as the default 'start.sh' script is currently incompatible with the Gcloud environment
# > The default working directory is '/workspace'
  - name: 'gcr.io/gold-hybrid-255313/builder'
    entrypoint: bash
    args:
      - '-c'
      - |
        chown -R dev:dev /workspace
        exec gosu dev:dev /bin/bash -c "./util/site/build-docs.sh build"
  - name: 'gcr.io/cloud-builders/gcloud'
    env:
    - 'PROJECT=gold-hybrid-255313'
    script: |
      #!/usr/bin/env bash
      build_dir="/workspace/build-site"

      # First, upload all (uncompressed) files
      gcloud storage cp -R --gzip-in-flight=js,css,html "${build_dir}/*" gs://${PROJECT}-prod
  - name: 'gcr.io/gold-hybrid-255313/builder'
    entrypoint: bash
    args:
      - '-c'
      - |
        # This script compresses the searchindex files, replacing the originals in-place.
        # (This is how 'content-encoding'-tagged files should be uploaded to gcloud buckets)
        exec gosu dev:dev /bin/bash -c "./util/site/post-build.sh compress_br"
  - name: 'gcr.io/cloud-builders/gcloud'
    env:
    - 'PROJECT=gold-hybrid-255313'
    script: |
      #!/usr/bin/env bash
      build_dir="/workspace/build-site"

      # Next, upload the brotli-compressed files.
      search_indexes=$(find ${build_dir}/ -type f -name '*searchindex.json')
      for f in $search_indexes; do
          echo "Uploading compressed file ${f}"
          # Get directory of file, relative to the build directory.
          # - var=${var#*//} # removes stuff from the begining up to //
          dir=$(dirname "${f#*"${build_dir}"/}")
          # When serving from gcloud buckets, file should be uploaded with an identical name as the
          # original, but compressed and with the matching 'content-encoding' and 'content-type' tags applied.
          gcloud storage cp \
                 --content-encoding=br \
                 --content-type=application/json \
                 -R \
                 "$f" "gs://${PROJECT}-prod/${dir}/"
      done
options:
  machineType: 'N1_HIGHCPU_8'
