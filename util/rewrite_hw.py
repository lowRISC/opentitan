#!/usr/bin/env python3
# Copyright lowRISC contributors (OpenTitan project).
# Licensed under the Apache License, Version 2.0, see LICENSE for details.
# SPDX-License-Identifier: Apache-2.0

import argparse
import subprocess
import os
import sys
from pathlib import Path


def global_replace(project_root, search, replace, verbose, subdir = None):
    print(f'global replace "{search}" by "{replace}"')
    dirs = []
    if subdir is not None:
        dirs.append(subdir)
    # Use ripgrep to find all matching files
    res = subprocess.run(
        ["rg", "-l", search] + dirs,
        capture_output = True,
    )
    # ripgrep returns 1 if there are no matches, 2 on error
    if res.returncode == 1:
        return
    assert res.returncode == 0, "ripgrep command failed"
    for path in res.stdout.splitlines():
        path = project_root / Path(os.fsdecode(path))
        if verbose:
            print(f"Patching {path}")
        # Read, patch, write
        f = path.read_text()
        f = f.replace(search, replace)
        path.write_text(f)


def delete_rule(lines, rule_name, target_name, file_name):
    try:
        start_idx = 0
        while start_idx < len(lines):
            start_idx = lines.index(f'{rule_name}(\n', start_idx)
            if target_name is None or lines[start_idx + 1] == f'    {target_name},\n':  # noqa: E231
                break
            start_idx = start_idx + 1
    except ValueError:
        assert False, \
            f"did not find beginning of rule {rule_name} (target name {target_name}) in {file_name}"
    try:
        end_idx = lines.index(')\n', start_idx + 1)
    except ValueError:
        assert False, \
            f"did not find end of rule {rule_name} (target name {target_name}) in {file_name}"
    return lines[:start_idx] + lines[end_idx + 1:], start_idx, lines[start_idx:end_idx + 1]


def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('-v', '--verbose', action='store_true')
    parser.add_argument('ip_dir', help='Path to the IP directory')
    parser.add_argument('--root', help='Path to the project root (if not specified, assume CWD)')
    parser.add_argument('-t', '--top', action='append', default=[],
                        help='Path to the top to edit (optional,c an be specified several times)')
    parser.add_argument('--hjson', help='Path to the IP hjson (optional)')
    parser.add_argument('-g', '--git', action='store_true', help='Create GIT commits')
    parser.add_argument('--keep-all-files', action='store_true',
                        help='Keep the all_files filegroup')
    parser.add_argument('--no-regs', action='store_true',
                        help='Do not generate headers for this block')

    args = parser.parse_args()

    commit_msg = "This commit was generated by running\n{}".format(" ".join(sys.argv))

    ip_dir = Path(args.ip_dir).resolve()
    assert ip_dir.exists() and ip_dir.is_dir(), \
        "IP directory invalid (must exists and be a directory)"
    ip_name = ip_dir.name
    project_root = Path(args.root if args.root is not None else Path.cwd()).resolve()
    assert project_root.exists() and \
        project_root.is_dir() and \
        (project_root / 'WORKSPACE').exists(), \
        "project root directory invalid"
    hjson_path = Path(args.hjson).resolve() if args.hjson is not None else None

    if args.verbose:
        print(f"Processing IP {ip_name}")
        print(f"- dir: {ip_dir}")
        print(f"- hjson: {hjson_path}")
        print(f"- root: {project_root}")

    if hjson_path is not None:
        assert hjson_path.exists() and hjson_path.is_file(), \
            f"HSJON path {hjson_path} invalid (must exists and be a file)"
        # Find the BUILD file for the hjson.
        hjson_build_path = (hjson_path.parent / 'BUILD').resolve()
        # We may need to go up several level for some ip_templates that don't have
        # a BUILD file in data/
        while not hjson_build_path.exists() and \
                hjson_build_path.parent.parent.is_relative_to(project_root):
            hjson_build_path = (hjson_build_path.parent.parent / 'BUILD').resolve()
        assert hjson_build_path.exists(), "could not find BUILD file for hjson"
        hjson_build = hjson_build_path.read_text().splitlines(keepends=True)
        # Find and delete the 'all_files' filegroup if needed.
        if not args.keep_all_files:
            hjson_build, all_files_idx, _ = delete_rule(
                hjson_build,
                "filegroup",
                'name = "all_files"',
                hjson_build_path
            )
        else:
            hjson_build.append('\n')
            all_files_idx = len(hjson_build)
        # Add hjson filegroup instead
        hjson_build = hjson_build[:all_files_idx] + [
            'filegroup(\n',
            '    name = "hjson",\n',
            '    srcs = ["{}"]\n'.format(hjson_path.name),
            ')\n'
        ] + hjson_build[all_files_idx:]
        # Write back.
        hjson_build_path.write_text(''.join(hjson_build))
        # Create bazel target for the hjson.
        hjson_bazel_target = "//{}:{}".format(
            hjson_build_path.parent.relative_to(project_root),
            (hjson_path.parent / 'hjson').relative_to(hjson_build_path.parent)
        )
    else:
        hjson_bazel_target = None

    # First step: edit IP's build file
    ip_build_path = ip_dir / 'BUILD'
    assert ip_build_path.exists(), f"expected a build file at {ip_build_path}"
    ip_build = ip_build_path.read_text().splitlines(keepends=True)
    # Expect to see a package visibility statement
    try:
        vis_index = ip_build.index('package(default_visibility = ["//visibility:public"])\n')
    except ValueError:
        assert False, \
            f"did not find visibility statement in {ip_build_path}, not touching this file"
    # Insert new load.
    ip_build.insert(vis_index, '\n')
    ip_build.insert(vis_index, 'load("//rules/opentitan:hw.bzl", "opentitan_ip")\n')
    # Find and delete the 'all_files' filegroup.
    if args.keep_all_files or hjson_path is None or ip_build_path.resolve() == hjson_build_path:
        ip_build.append('\n')
        all_files_idx = len(ip_build)
    else:
        ip_build, all_files_idx, _ = delete_rule(
            ip_build,
            "filegroup",
            'name = "all_files"',
            ip_build_path
        )
    # Remove filegroup and replace it with an opentitan_ip target.
    ip_build = ip_build[:all_files_idx] + [
        'opentitan_ip(\n',
        '    name = "{}",\n'.format(ip_name),
        '    hjson = "{}",\n'.format(hjson_bazel_target)
        if hjson_bazel_target is not None else '',
        '    files = glob(["**"])',
        ' + [\n' if ip_name == 'prim' else '',
        '        "//hw/ip/prim_generic:all_files",\n' if ip_name == 'prim' else '',
        '        "//hw/ip/prim_xilinx:all_files",\n' if ip_name == 'prim' else '',
        '        "//hw/ip/prim_xilinx_ultrascale:all_files",\n' if ip_name == 'prim' else '',
        '    ]' if ip_name == 'prim' else '',
        ',\n',
        ')\n'
    ] + ip_build[all_files_idx:]
    # Write back.
    ip_build_path.write_text(''.join(ip_build))

    # Global replacement:
    # '//path/to/ip:all_files' -> '//path/to/ip'
    if not args.keep_all_files:
        global_replace(
            project_root,
            '//{}:all_files'.format(ip_dir.relative_to(project_root)),
            '//{}'.format(ip_dir.relative_to(project_root)),
            args.verbose
        )

    # Run buildifier.
    subprocess.run(
        ["./bazelisk.sh", "run", "//quality:buildifier_fix"],
        check=True,
        cwd = project_root
    )

    if not args.no_regs:
        # Global replacement:
        # '//path/to/ip/data:ip_c_regs' -> '//hw/top:ip_c_regs'
        # Same for rust
        global_replace(
            project_root,
            '{}:{}_c_regs'.format(hjson_build_path.parent.relative_to(project_root), ip_name),
            f'hw/top:{ip_name}_c_regs',  # noqa: E231
            args.verbose
        )
        global_replace(
            project_root,
            '{}:{}_rust_regs'.format(hjson_build_path.parent.relative_to(project_root), ip_name),
            f'hw/top:{ip_name}_rust_regs',  # noqa: E231
            args.verbose
        )
        # Also add IP for the list in //hw/top
        hw_top_build_path = project_root / 'hw' / 'top' / 'BUILD'
        assert hw_top_build_path.exists()
        hw_top_build = hw_top_build_path.read_text().splitlines(keepends=True)
        try:
            top_ip_list_index = hw_top_build.index('IPS = [\n')
        except ValueError:
            assert False, f"did not find IP list in {hw_top_build_path}, not touching this file"
        try:
            top_ip_list_end_index = hw_top_build.index(']\n', top_ip_list_index + 1)
        except ValueError:
            assert False, \
                f"did not find end of IP list in {hw_top_build_path}, not touching this file"
        # Add IP.
        hw_top_build.insert(top_ip_list_end_index, f'    "{ip_name}",\n')  # noqa: E231
        # Write back.
        hw_top_build_path.write_text("".join(hw_top_build))
    # Edit tops.
    for top in args.top:
        top_build_path = Path(top) / 'BUILD'
        assert top_build_path.exists()
        # Read BUILD file.
        top_build = top_build_path.read_text().splitlines(keepends=True)
        # Find 'opentitan_top' rule.
        try:
            ot_top_index = top_build.index('opentitan_top(\n')
        except ValueError:
            assert False, f"did not find opentitan_top in {top_build_path}, not touching this file"
        try:
            ot_top_end_index = top_build.index(')\n', ot_top_index + 1)
        except ValueError:
            assert False, \
                f"did not find end of opentitan_top in {top_build_path}, not touching this file"
        # Find 'ips' list inside.
        try:
            ot_top_ips_index = top_build.index('    ips = [\n', ot_top_index, ot_top_end_index)
        except ValueError:
            assert False, \
                f"did not find ip list in opentitan_top in {top_build_path}, not touching this file"
        top_build.insert(ot_top_ips_index + 1,
                         '        "//{}",\n'.format(ip_dir.relative_to(project_root)))
        # Write back.
        top_build_path.write_text("".join(top_build))
    # Remove headers file in IP dir.
    if not args.no_regs:
        hjson_build = hjson_build_path.read_text().splitlines(keepends=True)
        # Remove load to //rules:autogen.bzl
        hjson_build, _, _ = delete_rule(
            hjson_build,
            'load',
            '"//rules:autogen.bzl"',
            hjson_build_path
        )
        # Remove autogen_hjson_c_header and autogen_hjson_rust_header
        hjson_build, _, _ = delete_rule(
            hjson_build,
            'autogen_hjson_c_header',
            None,
            hjson_build_path
        )
        hjson_build, _, _ = delete_rule(
            hjson_build,
            'autogen_hjson_rust_header',
            None,
            hjson_build_path
        )
        hjson_build_path.write_text(''.join(hjson_build))

    # Run buildifier.
    subprocess.run(
        ["./bazelisk.sh", "run", "//quality:buildifier_fix"],
        check=True,
        cwd = project_root
    )

    # Commit second change.
    if args.git:
        subprocess.run(
            ["git", "commit", "-vas", "-m",
             f"[bazel,{ip_name}] Use new rules to describe IP",  # noqa: E231
             "-m", commit_msg],
            check=True,
            cwd = project_root
        )


main()
